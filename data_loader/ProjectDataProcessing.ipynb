{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TypeToDateTime(data):\n",
    "    data['TIME'] = data['DATE'].astype(\"str\").str.cat(data['TIME_M'])#Combine Date&Time to one column\n",
    "    data['TIME'] = pd.to_datetime(data['TIME'], format = \"%Y%m%d%H:%M:%S.%f\")#Change type from string to datetime\n",
    "    data = data.drop(columns = ['TIME_M','DATE']).set_index('TIME')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuoteInput(i,j):\n",
    "    #path = os.path.abspath('TAQ')\n",
    "    #data = pd.read_csv(path+'/'+i+'_quote/'+str(j)+'.csv')\n",
    "    quote = pd.read_csv('/Users/yiyangqi/Documents/Spring 2020/Project/TAQ/'+i+'_quote/'+str(j)+'.csv')#import data\n",
    "    quote.loc[(quote.ASK == 0)|(quote.BID == 0), ['ASK','BID']] = np.nan#Since 0 ask or bid price are outliers, turn them into nan\n",
    "    quote = quote.dropna(subset=['BID','ASK'])#drop rows have 0 bid or ask price \n",
    "    quote = quote.loc[:,['BID','BIDSIZ','ASK','ASKSIZ','TIME_M','DATE']]#Only columns we need\n",
    "    #quote['TradeLabel'] = 0\n",
    "    return TypeToDateTime(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RawProcessing(data):\n",
    "    data.loc[:,'TimeInt'] = data.index.astype('int')\n",
    "    temp = data['TimeInt'].diff()\n",
    "    temp = temp.replace(0,np.nan) #convert data has no time change with last data to 0\n",
    "    temp = temp.fillna(method = 'ffill') #data has same time as last data, used data before last data\n",
    "    temp = temp.fillna(100) #set first time change to be 0\n",
    "    data.loc[:,'TimeChange'] = temp\n",
    "    temp = None #clear out\n",
    "    data.loc[data.TimeChange > 19800000000000, 'TimeChange'] = 100 #everyday is a new beginning \n",
    "    data = data.drop(columns = ['TimeInt'])\n",
    "    data.loc[:,'Spread '] = data.loc[:,'ASK'] - data.loc[:,'BID']#new features we need in the model\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BidAskImbalance(data):\n",
    "    data['BidAskImbalance'] = (data.loc[:,'BIDSIZ'] - data.loc[:,'ASKSIZ'])/(data.loc[:,'BIDSIZ'] + data.loc[:,'ASKSIZ'])#new features we need in the model\n",
    "    return data                                                                        \n",
    "                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TWAP(data):\n",
    "    #ser = pd.Series([\"2019010210:00:00.000000000\", \"2019010215:30:00.000000000\"] ) \n",
    "    #ser = pd.to_datetime(ser, format = \"%Y%m%d%H:%M:%S.%f\")\n",
    "    #Trade_Time_Int = ser.astype('int')[1]-ser.astype('int')[0] #Figure out integer number of trading time in a day\n",
    "    #Twap = dataa['TIME-Change']/dataa['TIME-int'].groupby(by = [dataa.index.day]).apply(lambda x: x-x[0])\n",
    "    #Twap = data['TimeChange']/Trade_Time_Int\n",
    "    \n",
    "    data['TwapAsk'] = (data['TimeChange']*data['ASK']).groupby(by = [data.index.day]).cumsum()/data['TimeChange'].groupby(by = [data.index.day]).cumsum()\n",
    "    #Calculated new features, we used sum of time change times price at that certain time point divided by sum of the time change till the same time\n",
    "    data['TwapBid'] = (data['TimeChange']*data['BID']).groupby(by = [data.index.day]).cumsum()/data['TimeChange'].groupby(by = [data.index.day]).cumsum()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VWAP(data):\n",
    "    data['VwapAsk']=(data['ASKSIZ']*data['ASK']).groupby(by = [data.index.day]).cumsum()/data['ASKSIZ'].groupby(by = [data.index.day]).cumsum()\n",
    "    #New features we used in model,we used sum of price*volume at that certain time point divided by sum of the volume till same time\n",
    "    data['VwapBid']=(data['BIDSIZ']*data['BID']).groupby(by = [data.index.day]).cumsum()/data['BIDSIZ'].groupby(by = [data.index.day]).cumsum()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = QuoteInput('TSLA',1)\n",
    "data = data['2019/01/07':'2019/01/08']\n",
    "data = RawProcessing(data)\n",
    "data = BidAskImbalance(data)\n",
    "data = TWAP(data)\n",
    "data = VWAP(data)\n",
    "data = (data-data.mean())/data.std()#standardize the data\n",
    "data.to_hdf('TSLA0107to0108.h5', complib='zlib', complevel =9, key = 'Jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,13):\n",
    "    data = QuoteInput('TSLA',j)\n",
    "    data = RawProcessing(data)\n",
    "    data = BidAskImbalance(data)\n",
    "    data = TWAP(data)\n",
    "    data = VWAP(data)\n",
    "    if j == 1:\n",
    "        temp = data\n",
    "    else:\n",
    "        frames = [temp,data]\n",
    "        temp = pd.concat(frames)\n",
    "\n",
    "#data = (temp-temp.min())/(temp.max()-temp.min())\n",
    "#data.to_hdf('data.h5', complib='zlib', complevel =9, key = 'TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (temp-temp.mean())/temp.std()\n",
    "data.to_hdf('TSLA.h5', complib='zlib', complevel =9, key = 'Jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below are data we tried, but didn't fit our calculation power. They are way too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DIRECTION(data):\n",
    "    #data['BidTemp'] = np.nan\n",
    "    #data['AskTemp'] = np.nan\n",
    "    for i in set(data.index.day):\n",
    "        data.loc[(data.TradeLabel == 0)& (data.index.day == i) , 'BidTemp'] = data.loc[(data.TradeLabel == 0)& (data.index.day == i) , 'BID']\n",
    "        data.loc[(data.TradeLabel == 0)& (data.index.day == i) , 'AskTemp'] = data.loc[(data.TradeLabel == 0)& (data.index.day == i) , 'ASK']\n",
    "        data.loc[data.index.day == i , 'AskTemp'] = data.loc[data.index.day == i , 'AskTemp'].fillna(method='ffill',limit = 1)\n",
    "        data.loc[data.index.day == i , 'BidTemp'] = data.loc[data.index.day == i , 'BidTemp'].fillna(method='ffill',limit = 1)\n",
    "    data['Direction'] = data.loc[:,'BidTemp']+data.loc[:,'AskTemp']-2*data.loc[:,'BID']\n",
    "    data.loc[:,'Direction'] = data.loc[:,'Direction'].fillna(0)\n",
    "    data.loc[data.TradeLabel == 0, 'Direction'] = 0\n",
    "    data.loc[data.Direction > 0, 'Direction'] = 1\n",
    "    data.loc[data.Direction < 0, 'Direction'] = -1 #Close to Ask = 1, Close to Bid = -1\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MovingAverage(data):\n",
    "    miu = data.rolling(1000).mean()\n",
    "    re = 0\n",
    "    for i in range(999):\n",
    "        miu[i] = (data[i]+re)/(i+1)\n",
    "        re += data[i]\n",
    "    return miu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiasRatio(data):\n",
    "    #data['TPTemp'] = np.nan\n",
    "    #data['BidMovingAverage'] = np.nan\n",
    "    #data['AskMovingAverage'] = np.nan\n",
    "    for i in set(data.index.day):\n",
    "        data.loc[(data.TradeLabel == 1)& (data.index.day == i) , 'TPTemp'] = data.loc[(data.TradeLabel == 1)& (data.index.day == i) , 'BID']\n",
    "        data.loc[(data.index.day == i) , 'BidMovingAverage'] = MovingAverage(data.loc[(data.index.day == i) , 'BID'])\n",
    "        data.loc[(data.index.day == i) , 'AskMovingAverage'] = MovingAverage(data.loc[(data.index.day == i) , 'ASK'])\n",
    "        data.loc[data.index.day == i , 'TPTemp'] = data.loc[data.index.day == i , 'TPTemp'].fillna(method='ffill')\n",
    "    data.loc[:,'TPTemp'] = data.loc[:,'TPTemp'].fillna(0)\n",
    "    #BidMovingAverage = data['BID'].groupby(by = [data.index.day]).apply(MovingAverage)\n",
    "    #AskMovingAverage = data['ASK'].groupby(by = [data.index.day]).apply(MovingAverage)\n",
    "    data['BidBias'] = (data.loc[:,'TPTemp'] - data['BidMovingAverage'])/data['BidMovingAverage']\n",
    "    data['AskBias'] = (data.loc[:,'TPTemp'] - data['AskMovingAverage'])/data['AskMovingAverage']\n",
    "    data.loc[data.TPTemp == 0, ['AskBias','BidBias']] = 0\n",
    "    BidMovingAverage = None\n",
    "    AskMovingAverage = None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataProcessing(data):\n",
    "    data = TWAP(data)\n",
    "    data = BidAskRatio(data)\n",
    "    data = VWAP(data)\n",
    "    data = DIRECTION(data)\n",
    "    data = BiasRatio(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalProcessing(data):\n",
    "    data.loc[:,['Direction','TradeLabel','TimeChange','ASKSIZ','BIDSIZ']] = data.loc[:, ['Direction','TradeLabel','TimeChange','ASKSIZ','BIDSIZ']].astype('int')\n",
    "    #data = data.drop(['SYM_ROOT','BidMovingAverage','AskMovingAverage'], axis=1)\n",
    "    data = data.reset_index()\n",
    "    data = data.drop(['TIME','TimeInt', 'AskTemp','BidTemp','TPTemp','BidMovingAverage','AskMovingAverage'], axis=1)\n",
    "    #data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange','ASKSIZ','BIDSIZ']]] = data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange','ASKSIZ','BIDSIZ']]].astype('float32')\n",
    "    #data.loc[:,'BidAskRatio'] = data.loc[:,'BidAskRatio'].fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RawData(data1,data2):\n",
    "    data = data1.append(data2, sort=False).sort_values(by = ['TIME'])\n",
    "    data = data.drop('SYM_ROOT',axis=1)\n",
    "    data['TimeInt'] = data.index.astype('int')\n",
    "    temp = data['TimeInt'].diff()\n",
    "    temp = temp.replace(0,np.nan) #convert data has no time change with last data to 0\n",
    "    temp = temp.fillna(method = 'ffill') #data has same time as last data, used data before last data\n",
    "    temp = temp.fillna(0) #set first time change to be 0\n",
    "    data['TimeChange'] = temp\n",
    "    temp = None #clear out\n",
    "    data.loc[data.TimeChange > 19800000000000, 'TimeChange'] = 0 #everyday is a new beginning \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TradeInput(i):\n",
    "    #path = os.path.abspath('TAQ')\n",
    "    #data = pd.read_csv(path+'/'+i+'_trade/'+i+'_trade.csv')\n",
    "    data = pd.read_csv('/Users/yiyangqi/Documents/Spring 2020/Project/TAQ/'+i+'_trade/'+i+'_trade.csv')\n",
    "    data['BID'] = data.loc[:,'PRICE']\n",
    "    data['ASK'] = data.loc[:,'PRICE']\n",
    "    data['BIDSIZ'] = data.loc[:,'SIZE']\n",
    "    data['ASKSIZ'] = data.loc[:,'SIZE']\n",
    "    data['TradeLabel'] = 1\n",
    "    data = data.loc[:,['BID','BIDSIZ','ASK','ASKSIZ','SYM_ROOT','TIME_M','DATE','TradeLabel']]\n",
    "    return TypeToDateTime(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyangqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "/Users/yiyangqi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "********************************************************\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "for i in ['TSLA','AAPL']:\n",
    "    trade = TradeInput(i)\n",
    "    for j in range(1,13):\n",
    "        if i == 'AAPL':\n",
    "            trade_temp = trade['2019/'+str(j)]\n",
    "        else:\n",
    "            if j == 12:\n",
    "                trade_temp = trade['2019/12/02':'2019/12/31']\n",
    "            else:\n",
    "                trade_temp = trade['2019/'+str(j)+'/2':'2019/'+str(j+1)+'/1']\n",
    "        quote = QuoteInput(i,j)\n",
    "        data = RawData(trade_temp,quote)\n",
    "        data = DataProcessing(data)\n",
    "        #data = data.drop(['TimeInt', 'AskTemp','BidTemp','TPTemp'], axis=1)\n",
    "        data = FinalProcessing(data)\n",
    "        if j  == 1:\n",
    "            maximun = data.max()\n",
    "            minimun = data.min()\n",
    "        else:\n",
    "            for k in maximun.index:\n",
    "                if data.max()[k] > maximun[k]:\n",
    "                    maximun[k] = data.max()[k]\n",
    "                if data.min()[k] < minimun[k]:\n",
    "                    minimun[k] = data.min()[k]\n",
    "        data.to_csv(i+str(j)+'.csv')\n",
    "        print('********************************************************')\n",
    "    maximun.to_csv(i+'maximun'+'.csv')\n",
    "    minimun.to_csv(i+'minimun'+'.csv')\n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'BID', 'BIDSIZ', 'ASK', 'ASKSIZ', 'TradeLabel',\n",
       "       'TimeChange', 'TwapAsk', 'TwapBid', 'BidAskRatio', 'VwapAsk', 'VwapBid',\n",
       "       'Direction', 'BidBias', 'AskBias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "快结束啦\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "快结束啦\n"
     ]
    }
   ],
   "source": [
    "for i in ['TSLA','AAPL']:\n",
    "    Max = pd.read_csv(i+'maximun.csv',header=None)\n",
    "    Min = pd.read_csv(i+'minimun.csv',header=None)\n",
    "    Max.columns = ['Index','Max']\n",
    "    Min.columns = ['Index','Min']\n",
    "    Max = Max.set_index('Index')\n",
    "    Min = Min.set_index('Index')\n",
    "    MaxMin = pd.concat([Max,Min],axis = 1)\n",
    "    for j in range(1,13):\n",
    "        data = pd.read_csv(i+str(j)+'.csv')\n",
    "        data = data.drop('Unnamed: 0', axis = 1)\n",
    "        for k in [elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange']]:\n",
    "            data.loc[:,k] = (data.loc[:,k]-MaxMin.loc[k,'Min'])/(MaxMin.loc[k,'Max'] - MaxMin.loc[k,'Min'])\n",
    "        data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange']]] = data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange']]].astype('float32')\n",
    "        data.loc[:,['Direction','TradeLabel','TimeChange']] = data.loc[:, ['Direction','TradeLabel','TimeChange']].astype('int')\n",
    "        data.to_csv(i+str(j)+'.csv')\n",
    "        print('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')\n",
    "    print('快结束啦')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "快结束啦\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "快结束啦\n"
     ]
    }
   ],
   "source": [
    "for i in ['TSLA','AAPL']:\n",
    "    Max = pd.read_csv(i+'maximun.csv',header=None)\n",
    "    Min = pd.read_csv(i+'minimun.csv',header=None)\n",
    "    Max.columns = ['Index','Max']\n",
    "    Min.columns = ['Index','Min']\n",
    "    Max = Max.set_index('Index')\n",
    "    Min = Min.set_index('Index')\n",
    "    MaxMin = pd.concat([Max,Min],axis = 1)\n",
    "    for j in range(1,13):\n",
    "        data = pd.read_csv('/Users/yiyangqi/Documents/Spring 2020/Project/'+i+'/'+i+str(j)+'.csv')\n",
    "        data = data.drop('Unnamed: 0', axis = 1)\n",
    "        data.loc[:,'ASKSIZ'] = (data.loc[:,'ASKSIZ']-MaxMin.loc['ASKSIZ','Min'])/(MaxMin.loc['ASKSIZ','Max'] - MaxMin.loc['ASKSIZ','Min'])\n",
    "        data.loc[:,'BIDSIZ'] = (data.loc[:,'BIDSIZ']-MaxMin.loc['BIDSIZ','Min'])/(MaxMin.loc['BIDSIZ','Max'] - MaxMin.loc['BIDSIZ','Min'])\n",
    "        data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange']]] = data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction','TimeChange']]].astype('float32')\n",
    "        data.loc[:,['Direction','TradeLabel','TimeChange']] = data.loc[:, ['Direction','TradeLabel','TimeChange']].astype('int')\n",
    "        data.to_csv('/Users/yiyangqi/Documents/Spring 2020/Project/'+i+'/'+i+str(j)+'.csv')\n",
    "        print('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')\n",
    "    print('快结束啦')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "**********************************************\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "for i in ['TSLA','AAPL']:\n",
    "    Max = pd.read_csv(i+'maximun.csv',header=None)\n",
    "    Min = pd.read_csv(i+'minimun.csv',header=None)\n",
    "    Max.columns = ['Index','Max']\n",
    "    Min.columns = ['Index','Min']\n",
    "    Max = Max.set_index('Index')\n",
    "    Min = Min.set_index('Index')\n",
    "    MaxMin = pd.concat([Max,Min],axis = 1)\n",
    "    for j in range(1,13):\n",
    "        data = pd.read_csv('/Users/yiyangqi/Documents/Spring 2020/Project/'+i+'_V2/'+i+str(j)+'.csv')\n",
    "        data = data.drop('Unnamed: 0', axis = 1)\n",
    "        data.loc[:,'TimeChange'] = (data.loc[:,'TimeChange']-MaxMin.loc['TimeChange','Min'])/(MaxMin.loc['TimeChange','Max'] - MaxMin.loc['TimeChange','Min'])\n",
    "        data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction']]] = data.loc[:,[elem for elem in list(data.columns) if elem not in ['TradeLabel','Direction']]].astype('float32')\n",
    "        data.loc[:,['Direction','TradeLabel']] = data.loc[:, ['Direction','TradeLabel']].astype('int')\n",
    "        data.to_hdf('/Users/yiyangqi/Documents/Spring 2020/Project/'+i+'.h5', key='month'+str(j),complevel=9, complib='blosc')\n",
    "        print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n",
    "    print('**********************************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
